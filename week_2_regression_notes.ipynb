{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMCZa2v+ylSBMluPCK2Q2P7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yeabwang/ML_zoom_camp/blob/main/week_2_regression_notes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# ====================================\n",
        "# 1. LOAD DATA\n",
        "# ====================================\n",
        "data = 'https://raw.githubusercontent.com/alexeygrigorev/mlbookcamp-code/master/chapter-02-car-price/data.csv'\n",
        "df = pd.read_csv(data)\n",
        "\n",
        "# ====================================\n",
        "# 2. DATA CLEANING\n",
        "# ====================================\n",
        "# Clean column names\n",
        "df.columns = df.columns.str.lower().str.replace(' ', '_')\n",
        "\n",
        "# Clean string values\n",
        "strings = list(df.dtypes[df.dtypes == 'object'].index)\n",
        "for col in strings:\n",
        "    df[col] = df[col].str.lower().str.replace(' ', '_')\n",
        "\n",
        "# ====================================\n",
        "# 3. TRAIN/VAL/TEST SPLIT (60/20/20)\n",
        "# ====================================\n",
        "n = len(df)\n",
        "n_val = int(n * 0.2)\n",
        "n_test = int(n * 0.2)\n",
        "n_train = n - n_val - n_test\n",
        "\n",
        "# Shuffle data\n",
        "idx = np.arange(n)\n",
        "np.random.seed(2)\n",
        "np.random.shuffle(idx)\n",
        "\n",
        "# Split data\n",
        "df_train = df.iloc[idx[:n_train]]\n",
        "df_val = df.iloc[idx[n_train:n_train+n_val]]\n",
        "df_test = df.iloc[idx[n_train+n_val:]]\n",
        "\n",
        "# Reset indices\n",
        "df_train = df_train.reset_index(drop=True)\n",
        "df_val = df_val.reset_index(drop=True)\n",
        "df_test = df_test.reset_index(drop=True)\n",
        "\n",
        "# Extract target variable (log transform)\n",
        "y_train = np.log1p(df_train.msrp.values)\n",
        "y_val = np.log1p(df_val.msrp.values)\n",
        "y_test = np.log1p(df_test.msrp.values)\n",
        "\n",
        "# Remove target from features\n",
        "del df_train['msrp']\n",
        "del df_val['msrp']\n",
        "del df_test['msrp']\n",
        "\n",
        "# ====================================\n",
        "# 4. DEFINE BASE FEATURES & CATEGORICAL MAPPING\n",
        "# ====================================\n",
        "base = ['engine_hp', 'engine_cylinders', 'highway_mpg', 'city_mpg', 'popularity']\n",
        "\n",
        "categorical_columns = [\n",
        "    'make', 'model', 'engine_fuel_type', 'driven_wheels',\n",
        "    'market_category', 'vehicle_size', 'vehicle_style'\n",
        "]\n",
        "\n",
        "# Get top 5 values for each categorical column (from training set only)\n",
        "categorical = {}\n",
        "for c in categorical_columns:\n",
        "    categorical[c] = list(df_train[c].value_counts().head().index)\n",
        "\n",
        "# ====================================\n",
        "# 5. FEATURE PREPARATION FUNCTION\n",
        "# ====================================\n",
        "def prepare_X(df):\n",
        "    df = df.copy()\n",
        "\n",
        "    # Create age feature\n",
        "    df['age'] = 2017 - df['year']\n",
        "    features = base + ['age']\n",
        "\n",
        "    # Create door indicator features\n",
        "    for v in [2, 3, 4]:\n",
        "        df['num_doors_%d' % v] = (df.number_of_doors == v).astype(int)\n",
        "        features.append('num_doors_%d' % v)\n",
        "\n",
        "    # Create categorical features (one-hot encoding)\n",
        "    for name, values in categorical.items():\n",
        "        for value in values:\n",
        "            df['%s_%s' % (name, value)] = (df[name] == value).astype(int)\n",
        "            features.append('%s_%s' % (name, value))\n",
        "\n",
        "    # Get feature matrix\n",
        "    df_num = df[features]\n",
        "    df_num = df_num.fillna(0)\n",
        "    X = df_num.values\n",
        "\n",
        "    return X\n",
        "\n",
        "# ====================================\n",
        "# 6. MODEL TRAINING FUNCTION (WITH REGULARIZATION)\n",
        "# ====================================\n",
        "def train_linear_regression_reg(X, y, r=0.001):\n",
        "    ones = np.ones(X.shape[0])\n",
        "    X = np.column_stack([ones, X])\n",
        "\n",
        "    XTX = X.T.dot(X)\n",
        "    XTX = XTX + r * np.eye(XTX.shape[0])\n",
        "\n",
        "    XTX_inv = np.linalg.inv(XTX)\n",
        "    w_full = XTX_inv.dot(X.T).dot(y)\n",
        "\n",
        "    return w_full[0], w_full[1:]\n",
        "\n",
        "# ====================================\n",
        "# 7. EVALUATION FUNCTION (RMSE)\n",
        "# ====================================\n",
        "def rmse(y, y_pred):\n",
        "    se = (y - y_pred) ** 2\n",
        "    mse = se.mean()\n",
        "    return np.sqrt(mse)\n",
        "\n",
        "# ====================================\n",
        "# 8. HYPERPARAMETER TUNING\n",
        "# ====================================\n",
        "print(\"Tuning regularization parameter:\")\n",
        "for r in [0.0, 0.00001, 0.0001, 0.001, 0.1, 1, 10]:\n",
        "    X_train = prepare_X(df_train)\n",
        "    w0, w = train_linear_regression_reg(X_train, y_train, r=r)\n",
        "\n",
        "    X_val = prepare_X(df_val)\n",
        "    y_pred = w0 + X_val.dot(w)\n",
        "    score = rmse(y_val, y_pred)\n",
        "\n",
        "    print(f\"r={r:7.5f}, RMSE={score:.4f}\")\n",
        "\n",
        "# ====================================\n",
        "# 9. FINAL MODEL TRAINING (TRAIN + VAL)\n",
        "# ====================================\n",
        "# Combine train and validation\n",
        "df_full_train = pd.concat([df_train, df_val])\n",
        "df_full_train = df_full_train.reset_index(drop=True)\n",
        "y_full_train = np.concatenate([y_train, y_val])\n",
        "\n",
        "# Train on combined data\n",
        "X_full_train = prepare_X(df_full_train)\n",
        "w0, w = train_linear_regression_reg(X_full_train, y_full_train, r=0.001)\n",
        "\n",
        "# ====================================\n",
        "# 10. FINAL EVALUATION ON TEST SET\n",
        "# ====================================\n",
        "X_test = prepare_X(df_test)\n",
        "y_pred = w0 + X_test.dot(w)\n",
        "final_score = rmse(y_test, y_pred)\n",
        "\n",
        "print(f\"\\nFinal Test RMSE: {final_score:.4f}\")\n",
        "\n",
        "# ====================================\n",
        "# 11. PREDICTION ON SINGLE EXAMPLE\n",
        "# ====================================\n",
        "car = df_test.iloc[20].to_dict()\n",
        "df_small = pd.DataFrame([car])\n",
        "X_small = prepare_X(df_small)\n",
        "\n",
        "y_pred = w0 + X_small.dot(w)\n",
        "predicted_price = np.expm1(y_pred[0])\n",
        "actual_price = np.expm1(y_test[20])\n",
        "\n",
        "print(f\"\\nPrediction Example:\")\n",
        "print(f\"Predicted price: ${predicted_price:,.2f}\")\n",
        "print(f\"Actual price: ${actual_price:,.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NBMjkqbYd5H",
        "outputId": "0a41123b-1059-48b7-8a8e-91e0fcb1a0f9"
      },
      "execution_count": 311,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tuning regularization parameter:\n",
            "r=0.00000, RMSE=53.7037\n",
            "r=0.00001, RMSE=0.4608\n",
            "r=0.00010, RMSE=0.4608\n",
            "r=0.00100, RMSE=0.4608\n",
            "r=0.10000, RMSE=0.4609\n",
            "r=1.00000, RMSE=0.4616\n",
            "r=10.00000, RMSE=0.4726\n",
            "\n",
            "Final Test RMSE: 0.4601\n",
            "\n",
            "Prediction Example:\n",
            "Predicted price: $41,459.34\n",
            "Actual price: $35,000.00\n"
          ]
        }
      ]
    }
  ]
}